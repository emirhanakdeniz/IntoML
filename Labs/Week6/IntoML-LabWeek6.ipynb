{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:58:56.523800Z",
     "start_time": "2024-04-03T12:58:54.225207Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/akden/PycharmProjects/IntoML/Labs/Week6/data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:59:17.280877Z",
     "start_time": "2024-04-03T12:59:17.268436Z"
    }
   },
   "id": "49950a62a962b8ae",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302         M        17.99         10.38          122.80     1001.0   \n1    842517         M        20.57         17.77          132.90     1326.0   \n2  84300903         M        19.69         21.25          130.00     1203.0   \n3  84348301         M        11.42         20.38           77.58      386.1   \n4  84358402         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n0  ...          17.33           184.60      2019.0            0.1622   \n1  ...          23.41           158.80      1956.0            0.1238   \n2  ...          25.53           152.50      1709.0            0.1444   \n3  ...          26.50            98.87       567.7            0.2098   \n4  ...          16.67           152.20      1575.0            0.1374   \n\n   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n0             0.6656           0.7119                0.2654          0.4601   \n1             0.1866           0.2416                0.1860          0.2750   \n2             0.4245           0.4504                0.2430          0.3613   \n3             0.8663           0.6869                0.2575          0.6638   \n4             0.2050           0.4000                0.1625          0.2364   \n\n   fractal_dimension_worst  Unnamed: 32  \n0                  0.11890          NaN  \n1                  0.08902          NaN  \n2                  0.08758          NaN  \n3                  0.17300          NaN  \n4                  0.07678          NaN  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n      <th>Unnamed: 32</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 33 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:59:22.895210Z",
     "start_time": "2024-04-03T12:59:22.864433Z"
    }
   },
   "id": "25e966c18dae56e0",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 33 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       569 non-null    int64  \n",
      " 1   diagnosis                569 non-null    object \n",
      " 2   radius_mean              569 non-null    float64\n",
      " 3   texture_mean             569 non-null    float64\n",
      " 4   perimeter_mean           569 non-null    float64\n",
      " 5   area_mean                569 non-null    float64\n",
      " 6   smoothness_mean          569 non-null    float64\n",
      " 7   compactness_mean         569 non-null    float64\n",
      " 8   concavity_mean           569 non-null    float64\n",
      " 9   concave points_mean      569 non-null    float64\n",
      " 10  symmetry_mean            569 non-null    float64\n",
      " 11  fractal_dimension_mean   569 non-null    float64\n",
      " 12  radius_se                569 non-null    float64\n",
      " 13  texture_se               569 non-null    float64\n",
      " 14  perimeter_se             569 non-null    float64\n",
      " 15  area_se                  569 non-null    float64\n",
      " 16  smoothness_se            569 non-null    float64\n",
      " 17  compactness_se           569 non-null    float64\n",
      " 18  concavity_se             569 non-null    float64\n",
      " 19  concave points_se        569 non-null    float64\n",
      " 20  symmetry_se              569 non-null    float64\n",
      " 21  fractal_dimension_se     569 non-null    float64\n",
      " 22  radius_worst             569 non-null    float64\n",
      " 23  texture_worst            569 non-null    float64\n",
      " 24  perimeter_worst          569 non-null    float64\n",
      " 25  area_worst               569 non-null    float64\n",
      " 26  smoothness_worst         569 non-null    float64\n",
      " 27  compactness_worst        569 non-null    float64\n",
      " 28  concavity_worst          569 non-null    float64\n",
      " 29  concave points_worst     569 non-null    float64\n",
      " 30  symmetry_worst           569 non-null    float64\n",
      " 31  fractal_dimension_worst  569 non-null    float64\n",
      " 32  Unnamed: 32              0 non-null      float64\n",
      "dtypes: float64(31), int64(1), object(1)\n",
      "memory usage: 146.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:59:31.616639Z",
     "start_time": "2024-04-03T12:59:31.602789Z"
    }
   },
   "id": "16334dcea113f39a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data.drop([\"Unnamed: 32\", \"id\"], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T12:59:54.081705Z",
     "start_time": "2024-04-03T12:59:54.075100Z"
    }
   },
   "id": "e5c50d8d3da9263b",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data.diagnosis = [1 if each =='M' else 0 for each in data.diagnosis]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:00:12.419320Z",
     "start_time": "2024-04-03T13:00:12.414182Z"
    }
   },
   "id": "28dc36f4973d1311",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y = data.diagnosis.values\n",
    "x_data = data.drop([\"diagnosis\"], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:00:36.003859Z",
     "start_time": "2024-04-03T13:00:35.995938Z"
    }
   },
   "id": "302ec1c093dd071c",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:01:36.533081Z",
     "start_time": "2024-04-03T13:01:36.525806Z"
    }
   },
   "id": "b021c54357c1513",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n0       0.004229      0.002440        0.028867   0.235308         0.000028   \n1       0.004835      0.004177        0.031241   0.311707         0.000020   \n2       0.004629      0.004995        0.030559   0.282793         0.000026   \n3       0.002685      0.004791        0.018237   0.090762         0.000033   \n4       0.004770      0.003371        0.031758   0.304890         0.000024   \n..           ...           ...             ...        ...              ...   \n564     0.005068      0.005263        0.033380   0.347673         0.000026   \n565     0.004732      0.006641        0.030842   0.296427         0.000023   \n566     0.003902      0.006601        0.025458   0.201716         0.000020   \n567     0.004843      0.006895        0.032934   0.297367         0.000028   \n568     0.001824      0.005769        0.011265   0.042548         0.000012   \n\n     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n0            0.000065        0.000071             0.000035       0.000057   \n1            0.000018        0.000020             0.000016       0.000043   \n2            0.000038        0.000046             0.000030       0.000049   \n3            0.000067        0.000057             0.000025       0.000061   \n4            0.000031        0.000047             0.000025       0.000043   \n..                ...             ...                  ...            ...   \n564          0.000027        0.000057             0.000033       0.000041   \n565          0.000024        0.000034             0.000023       0.000041   \n566          0.000024        0.000022             0.000012       0.000037   \n567          0.000065        0.000083             0.000036       0.000056   \n568          0.000010        0.000000             0.000000       0.000037   \n\n     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n0                  0.000019  ...      0.005966       0.004074   \n1                  0.000013  ...      0.005874       0.005503   \n2                  0.000014  ...      0.005541       0.006001   \n3                  0.000023  ...      0.003505       0.006229   \n4                  0.000014  ...      0.005299       0.003919   \n..                      ...  ...           ...            ...   \n564                0.000013  ...      0.005983       0.006206   \n565                0.000013  ...      0.005569       0.008992   \n566                0.000013  ...      0.004462       0.008021   \n567                0.000016  ...      0.006051       0.009267   \n568                0.000014  ...      0.002223       0.007139   \n\n     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n0           0.043394    0.474612          0.000038           0.000156   \n1           0.037330    0.459803          0.000029           0.000044   \n2           0.035849    0.401740          0.000034           0.000100   \n3           0.023242    0.133451          0.000049           0.000204   \n4           0.035778    0.370240          0.000032           0.000048   \n..               ...         ...               ...                ...   \n564         0.039046    0.476493          0.000033           0.000050   \n565         0.036436    0.406911          0.000027           0.000045   \n566         0.029784    0.264222          0.000027           0.000073   \n567         0.043394    0.428068          0.000039           0.000204   \n568         0.013907    0.063141          0.000021           0.000015   \n\n     concavity_worst  concave points_worst  symmetry_worst  \\\n0           0.000167              0.000062        0.000108   \n1           0.000057              0.000044        0.000065   \n2           0.000106              0.000057        0.000085   \n3           0.000161              0.000061        0.000156   \n4           0.000094              0.000038        0.000056   \n..               ...                   ...             ...   \n564         0.000097              0.000052        0.000048   \n565         0.000076              0.000038        0.000060   \n566         0.000080              0.000033        0.000052   \n567         0.000221              0.000062        0.000096   \n568         0.000000              0.000000        0.000067   \n\n     fractal_dimension_worst  \n0                   0.000028  \n1                   0.000021  \n2                   0.000021  \n3                   0.000041  \n4                   0.000018  \n..                       ...  \n564                 0.000017  \n565                 0.000016  \n566                 0.000018  \n567                 0.000029  \n568                 0.000017  \n\n[569 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>symmetry_mean</th>\n      <th>fractal_dimension_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.004229</td>\n      <td>0.002440</td>\n      <td>0.028867</td>\n      <td>0.235308</td>\n      <td>0.000028</td>\n      <td>0.000065</td>\n      <td>0.000071</td>\n      <td>0.000035</td>\n      <td>0.000057</td>\n      <td>0.000019</td>\n      <td>...</td>\n      <td>0.005966</td>\n      <td>0.004074</td>\n      <td>0.043394</td>\n      <td>0.474612</td>\n      <td>0.000038</td>\n      <td>0.000156</td>\n      <td>0.000167</td>\n      <td>0.000062</td>\n      <td>0.000108</td>\n      <td>0.000028</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.004835</td>\n      <td>0.004177</td>\n      <td>0.031241</td>\n      <td>0.311707</td>\n      <td>0.000020</td>\n      <td>0.000018</td>\n      <td>0.000020</td>\n      <td>0.000016</td>\n      <td>0.000043</td>\n      <td>0.000013</td>\n      <td>...</td>\n      <td>0.005874</td>\n      <td>0.005503</td>\n      <td>0.037330</td>\n      <td>0.459803</td>\n      <td>0.000029</td>\n      <td>0.000044</td>\n      <td>0.000057</td>\n      <td>0.000044</td>\n      <td>0.000065</td>\n      <td>0.000021</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.004629</td>\n      <td>0.004995</td>\n      <td>0.030559</td>\n      <td>0.282793</td>\n      <td>0.000026</td>\n      <td>0.000038</td>\n      <td>0.000046</td>\n      <td>0.000030</td>\n      <td>0.000049</td>\n      <td>0.000014</td>\n      <td>...</td>\n      <td>0.005541</td>\n      <td>0.006001</td>\n      <td>0.035849</td>\n      <td>0.401740</td>\n      <td>0.000034</td>\n      <td>0.000100</td>\n      <td>0.000106</td>\n      <td>0.000057</td>\n      <td>0.000085</td>\n      <td>0.000021</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.002685</td>\n      <td>0.004791</td>\n      <td>0.018237</td>\n      <td>0.090762</td>\n      <td>0.000033</td>\n      <td>0.000067</td>\n      <td>0.000057</td>\n      <td>0.000025</td>\n      <td>0.000061</td>\n      <td>0.000023</td>\n      <td>...</td>\n      <td>0.003505</td>\n      <td>0.006229</td>\n      <td>0.023242</td>\n      <td>0.133451</td>\n      <td>0.000049</td>\n      <td>0.000204</td>\n      <td>0.000161</td>\n      <td>0.000061</td>\n      <td>0.000156</td>\n      <td>0.000041</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.004770</td>\n      <td>0.003371</td>\n      <td>0.031758</td>\n      <td>0.304890</td>\n      <td>0.000024</td>\n      <td>0.000031</td>\n      <td>0.000047</td>\n      <td>0.000025</td>\n      <td>0.000043</td>\n      <td>0.000014</td>\n      <td>...</td>\n      <td>0.005299</td>\n      <td>0.003919</td>\n      <td>0.035778</td>\n      <td>0.370240</td>\n      <td>0.000032</td>\n      <td>0.000048</td>\n      <td>0.000094</td>\n      <td>0.000038</td>\n      <td>0.000056</td>\n      <td>0.000018</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>0.005068</td>\n      <td>0.005263</td>\n      <td>0.033380</td>\n      <td>0.347673</td>\n      <td>0.000026</td>\n      <td>0.000027</td>\n      <td>0.000057</td>\n      <td>0.000033</td>\n      <td>0.000041</td>\n      <td>0.000013</td>\n      <td>...</td>\n      <td>0.005983</td>\n      <td>0.006206</td>\n      <td>0.039046</td>\n      <td>0.476493</td>\n      <td>0.000033</td>\n      <td>0.000050</td>\n      <td>0.000097</td>\n      <td>0.000052</td>\n      <td>0.000048</td>\n      <td>0.000017</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>0.004732</td>\n      <td>0.006641</td>\n      <td>0.030842</td>\n      <td>0.296427</td>\n      <td>0.000023</td>\n      <td>0.000024</td>\n      <td>0.000034</td>\n      <td>0.000023</td>\n      <td>0.000041</td>\n      <td>0.000013</td>\n      <td>...</td>\n      <td>0.005569</td>\n      <td>0.008992</td>\n      <td>0.036436</td>\n      <td>0.406911</td>\n      <td>0.000027</td>\n      <td>0.000045</td>\n      <td>0.000076</td>\n      <td>0.000038</td>\n      <td>0.000060</td>\n      <td>0.000016</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>0.003902</td>\n      <td>0.006601</td>\n      <td>0.025458</td>\n      <td>0.201716</td>\n      <td>0.000020</td>\n      <td>0.000024</td>\n      <td>0.000022</td>\n      <td>0.000012</td>\n      <td>0.000037</td>\n      <td>0.000013</td>\n      <td>...</td>\n      <td>0.004462</td>\n      <td>0.008021</td>\n      <td>0.029784</td>\n      <td>0.264222</td>\n      <td>0.000027</td>\n      <td>0.000073</td>\n      <td>0.000080</td>\n      <td>0.000033</td>\n      <td>0.000052</td>\n      <td>0.000018</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>0.004843</td>\n      <td>0.006895</td>\n      <td>0.032934</td>\n      <td>0.297367</td>\n      <td>0.000028</td>\n      <td>0.000065</td>\n      <td>0.000083</td>\n      <td>0.000036</td>\n      <td>0.000056</td>\n      <td>0.000016</td>\n      <td>...</td>\n      <td>0.006051</td>\n      <td>0.009267</td>\n      <td>0.043394</td>\n      <td>0.428068</td>\n      <td>0.000039</td>\n      <td>0.000204</td>\n      <td>0.000221</td>\n      <td>0.000062</td>\n      <td>0.000096</td>\n      <td>0.000029</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>0.001824</td>\n      <td>0.005769</td>\n      <td>0.011265</td>\n      <td>0.042548</td>\n      <td>0.000012</td>\n      <td>0.000010</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000037</td>\n      <td>0.000014</td>\n      <td>...</td>\n      <td>0.002223</td>\n      <td>0.007139</td>\n      <td>0.013907</td>\n      <td>0.063141</td>\n      <td>0.000021</td>\n      <td>0.000015</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000067</td>\n      <td>0.000017</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:01:40.070976Z",
     "start_time": "2024-04-03T13:01:40.043880Z"
    }
   },
   "id": "dfb1100b1bda8f52",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split (x,y,test_size=0.20,random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:01:48.360642Z",
     "start_time": "2024-04-03T13:01:48.354533Z"
    }
   },
   "id": "405317720daaf893",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(455, 30)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.T\n",
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:02:50.666807Z",
     "start_time": "2024-04-03T13:02:50.659591Z"
    }
   },
   "id": "de7e6df78144c4a9",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_test = x_test.T\n",
    "y_train = y_train.T\n",
    "y_test = y_test.T"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:03:17.601667Z",
     "start_time": "2024-04-03T13:03:17.596467Z"
    }
   },
   "id": "494254781727198a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 114)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:03:23.780111Z",
     "start_time": "2024-04-03T13:03:23.775589Z"
    }
   },
   "id": "e8360f24ca21fdf3",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(455,)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:03:29.503471Z",
     "start_time": "2024-04-03T13:03:29.497913Z"
    }
   },
   "id": "5ee902930287fbbc",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(114,)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:03:34.415696Z",
     "start_time": "2024-04-03T13:03:34.409482Z"
    }
   },
   "id": "54e6df1ab2015612",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1), 0.01)\n",
    "    b = 0.0\n",
    "    return w,b"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:04:03.570705Z",
     "start_time": "2024-04-03T13:04:03.565378Z"
    }
   },
   "id": "771376be777ceed3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:04:33.290929Z",
     "start_time": "2024-04-03T13:04:33.286433Z"
    }
   },
   "id": "315c8e8e98c136a3",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.5"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:04:36.059385Z",
     "start_time": "2024-04-03T13:04:36.052826Z"
    }
   },
   "id": "66988b9a59246659",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    z = np.dot(w.T,x_train) + b \n",
    "    y_head = sigmoid(z) \n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head) \n",
    "    cost = (np.sum(loss))/x_train.shape[1]   \n",
    "\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1]  \n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]              \n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "\n",
    "    return cost,gradients"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:04:57.457837Z",
     "start_time": "2024-04-03T13:04:57.450778Z"
    }
   },
   "id": "d72dbbda320aaafa",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    \n",
    "    for i in range(number_of_iterarion): \n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train) \n",
    "        cost_list.append(cost) \n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]  \n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]   \n",
    "        if i % 10 == 0:\n",
    "            cost_list2.append(cost) \n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    parameters = {\"weight\": w,\"bias\": b} \n",
    "    plt.plot(index,cost_list2) \n",
    "    plt.xticks(index,rotation='vertical') \n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:05:10.691709Z",
     "start_time": "2024-04-03T13:05:10.683013Z"
    }
   },
   "id": "6d521194742606ed",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict(w,b,x_test):\n",
    "    \n",
    "    z = sigmoid(np.dot(w.T,x_test)+b) \n",
    "    Y_prediction = np.zeros((1,x_test.shape[1])) #(1,114) \n",
    "    \n",
    "    for i in range(z.shape[1]): \n",
    "        if z[0,i]<= 0.5: \n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "                        \n",
    "    return Y_prediction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:06:06.168642Z",
     "start_time": "2024-04-03T13:06:06.161906Z"
    }
   },
   "id": "2d9bab99b00833d6",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (455,) (1,30) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 12\u001B[0m\n\u001B[0;32m      8\u001B[0m     y_prediction_test \u001B[38;5;241m=\u001B[39m predict(parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m\"\u001B[39m],parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbias\u001B[39m\u001B[38;5;124m\"\u001B[39m],x_test)\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest accuracy: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;241m100\u001B[39m \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39mabs(y_prediction_test \u001B[38;5;241m-\u001B[39m y_test)) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m))\n\u001B[1;32m---> 12\u001B[0m logistic_regression(x_train, y_train, x_test, y_test,learning_rate \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m3\u001B[39m, num_iterations \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m300\u001B[39m)\n",
      "Cell \u001B[1;32mIn[29], line 6\u001B[0m, in \u001B[0;36mlogistic_regression\u001B[1;34m(x_train, y_train, x_test, y_test, learning_rate, num_iterations)\u001B[0m\n\u001B[0;32m      3\u001B[0m dimension \u001B[38;5;241m=\u001B[39m  x_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]  \n\u001B[0;32m      4\u001B[0m w,b \u001B[38;5;241m=\u001B[39m initialize_weights_and_bias(dimension)\n\u001B[1;32m----> 6\u001B[0m parameters, gradients, cost_list \u001B[38;5;241m=\u001B[39m update(w, b, x_train, y_train, learning_rate,num_iterations)\n\u001B[0;32m      8\u001B[0m y_prediction_test \u001B[38;5;241m=\u001B[39m predict(parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m\"\u001B[39m],parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbias\u001B[39m\u001B[38;5;124m\"\u001B[39m],x_test)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest accuracy: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;241m100\u001B[39m \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(np\u001B[38;5;241m.\u001B[39mabs(y_prediction_test \u001B[38;5;241m-\u001B[39m y_test)) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m))\n",
      "Cell \u001B[1;32mIn[23], line 7\u001B[0m, in \u001B[0;36mupdate\u001B[1;34m(w, b, x_train, y_train, learning_rate, number_of_iterarion)\u001B[0m\n\u001B[0;32m      4\u001B[0m index \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(number_of_iterarion): \n\u001B[1;32m----> 7\u001B[0m     cost,gradients \u001B[38;5;241m=\u001B[39m forward_backward_propagation(w,b,x_train,y_train) \n\u001B[0;32m      8\u001B[0m     cost_list\u001B[38;5;241m.\u001B[39mappend(cost) \n\u001B[0;32m      9\u001B[0m     w \u001B[38;5;241m=\u001B[39m w \u001B[38;5;241m-\u001B[39m learning_rate \u001B[38;5;241m*\u001B[39m gradients[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mderivative_weight\u001B[39m\u001B[38;5;124m\"\u001B[39m]  \n",
      "Cell \u001B[1;32mIn[22], line 4\u001B[0m, in \u001B[0;36mforward_backward_propagation\u001B[1;34m(w, b, x_train, y_train)\u001B[0m\n\u001B[0;32m      2\u001B[0m z \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(w\u001B[38;5;241m.\u001B[39mT,x_train) \u001B[38;5;241m+\u001B[39m b \n\u001B[0;32m      3\u001B[0m y_head \u001B[38;5;241m=\u001B[39m sigmoid(z) \n\u001B[1;32m----> 4\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39my_train\u001B[38;5;241m*\u001B[39mnp\u001B[38;5;241m.\u001B[39mlog(y_head)\u001B[38;5;241m-\u001B[39m(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39my_train)\u001B[38;5;241m*\u001B[39mnp\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39my_head) \n\u001B[0;32m      5\u001B[0m cost \u001B[38;5;241m=\u001B[39m (np\u001B[38;5;241m.\u001B[39msum(loss))\u001B[38;5;241m/\u001B[39mx_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]   \n\u001B[0;32m      7\u001B[0m derivative_weight \u001B[38;5;241m=\u001B[39m (np\u001B[38;5;241m.\u001B[39mdot(x_train,((y_head\u001B[38;5;241m-\u001B[39my_train)\u001B[38;5;241m.\u001B[39mT)))\u001B[38;5;241m/\u001B[39mx_train\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]  \n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (455,) (1,30) "
     ]
    }
   ],
   "source": [
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate ,  num_iterations):\n",
    "    \n",
    "    dimension =  x_train.shape[0]  \n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "\n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "   \n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    \n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 3, num_iterations = 300)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:09:06.379375Z",
     "start_time": "2024-04-03T13:09:06.306694Z"
    }
   },
   "id": "16beab1d774928ac",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [30, 455]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m linear_model\n\u001B[0;32m      2\u001B[0m lr \u001B[38;5;241m=\u001B[39m linear_model\u001B[38;5;241m.\u001B[39mLogisticRegression(random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m,max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m40\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m lr\u001B[38;5;241m.\u001B[39mfit(x_train\u001B[38;5;241m.\u001B[39mT,y_train\u001B[38;5;241m.\u001B[39mT)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1207\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1204\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1205\u001B[0m     _dtype \u001B[38;5;241m=\u001B[39m [np\u001B[38;5;241m.\u001B[39mfloat64, np\u001B[38;5;241m.\u001B[39mfloat32]\n\u001B[1;32m-> 1207\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m   1208\u001B[0m     X,\n\u001B[0;32m   1209\u001B[0m     y,\n\u001B[0;32m   1210\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1211\u001B[0m     dtype\u001B[38;5;241m=\u001B[39m_dtype,\n\u001B[0;32m   1212\u001B[0m     order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1213\u001B[0m     accept_large_sparse\u001B[38;5;241m=\u001B[39msolver \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mliblinear\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msag\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   1214\u001B[0m )\n\u001B[0;32m   1215\u001B[0m check_classification_targets(y)\n\u001B[0;32m   1216\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\base.py:621\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    619\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 621\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\utils\\validation.py:1165\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1147\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1148\u001B[0m     X,\n\u001B[0;32m   1149\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1160\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1161\u001B[0m )\n\u001B[0;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m-> 1165\u001B[0m check_consistent_length(X, y)\n\u001B[0;32m   1167\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, y\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\utils\\validation.py:409\u001B[0m, in \u001B[0;36mcheck_consistent_length\u001B[1;34m(*arrays)\u001B[0m\n\u001B[0;32m    407\u001B[0m uniques \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(lengths)\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(uniques) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 409\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    410\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound input variables with inconsistent numbers of samples: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    411\u001B[0m         \u001B[38;5;241m%\u001B[39m [\u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lengths]\n\u001B[0;32m    412\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Found input variables with inconsistent numbers of samples: [30, 455]"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lr = linear_model.LogisticRegression(random_state=42,max_iter=40)\n",
    "lr.fit(x_train.T,y_train.T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:09:10.153542Z",
     "start_time": "2024-04-03T13:09:10.046599Z"
    }
   },
   "id": "f6447fcc1aa3dd3f",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m lr\u001B[38;5;241m.\u001B[39mpredict(x_test\u001B[38;5;241m.\u001B[39mT)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001B[0m, in \u001B[0;36mLinearClassifierMixin.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;124;03mPredict class labels for samples in X.\u001B[39;00m\n\u001B[0;32m    439\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;124;03m    Vector containing the class labels for each sample.\u001B[39;00m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    450\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m--> 451\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecision_function(X)\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(scores\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    453\u001B[0m     indices \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(scores \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:429\u001B[0m, in \u001B[0;36mLinearClassifierMixin.decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecision_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    411\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;124;03m    Predict confidence scores for samples.\u001B[39;00m\n\u001B[0;32m    413\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;124;03m        this class would be predicted.\u001B[39;00m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 429\u001B[0m     check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    430\u001B[0m     xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[0;32m    432\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\utils\\validation.py:1462\u001B[0m, in \u001B[0;36mcheck_is_fitted\u001B[1;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[0;32m   1459\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is not an estimator instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (estimator))\n\u001B[0;32m   1461\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001B[1;32m-> 1462\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(msg \u001B[38;5;241m%\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(estimator)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m})\n",
      "\u001B[1;31mNotFittedError\u001B[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(x_test.T)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:09:12.989035Z",
     "start_time": "2024-04-03T13:09:12.833089Z"
    }
   },
   "id": "8cb0f74b5e424d09",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[32], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest accuracy \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(lr\u001B[38;5;241m.\u001B[39mscore(x_test\u001B[38;5;241m.\u001B[39mT,y_test\u001B[38;5;241m.\u001B[39mT)))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\base.py:705\u001B[0m, in \u001B[0;36mClassifierMixin.score\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    680\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    681\u001B[0m \u001B[38;5;124;03mReturn the mean accuracy on the given test data and labels.\u001B[39;00m\n\u001B[0;32m    682\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    701\u001B[0m \u001B[38;5;124;03m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001B[39;00m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m accuracy_score\n\u001B[1;32m--> 705\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m accuracy_score(y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(X), sample_weight\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:451\u001B[0m, in \u001B[0;36mLinearClassifierMixin.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    437\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;124;03mPredict class labels for samples in X.\u001B[39;00m\n\u001B[0;32m    439\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    448\u001B[0m \u001B[38;5;124;03m    Vector containing the class labels for each sample.\u001B[39;00m\n\u001B[0;32m    449\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    450\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[1;32m--> 451\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecision_function(X)\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(scores\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    453\u001B[0m     indices \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(scores \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:429\u001B[0m, in \u001B[0;36mLinearClassifierMixin.decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    410\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecision_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    411\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;124;03m    Predict confidence scores for samples.\u001B[39;00m\n\u001B[0;32m    413\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;124;03m        this class would be predicted.\u001B[39;00m\n\u001B[0;32m    428\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 429\u001B[0m     check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    430\u001B[0m     xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[0;32m    432\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\IntoML\\Lib\\site-packages\\sklearn\\utils\\validation.py:1462\u001B[0m, in \u001B[0;36mcheck_is_fitted\u001B[1;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[0;32m   1459\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is not an estimator instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (estimator))\n\u001B[0;32m   1461\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001B[1;32m-> 1462\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(msg \u001B[38;5;241m%\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(estimator)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m})\n",
      "\u001B[1;31mNotFittedError\u001B[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "print(\"test accuracy {}\".format(lr.score(x_test.T,y_test.T)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T13:09:17.820676Z",
     "start_time": "2024-04-03T13:09:17.760003Z"
    }
   },
   "id": "f9d9059f9d31aaf7",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "48f21e023ec234dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
